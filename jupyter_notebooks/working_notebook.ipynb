{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "55431f2f-37f6-4773-8c64-1ea7d02de485",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "617bf020-e712-4d23-8d8e-90edf6b232d3",
   "metadata": {},
   "source": [
    "## data to check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8f29b96-602a-40ec-9adb-d7f8c5f61d2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train ... (17, 2500, 7)\n",
      "X_test ... (4, 2500, 7)\n",
      "y_train ... (17, 2500, 3)\n",
      "y_test ... (4, 2500, 3)\n"
     ]
    }
   ],
   "source": [
    "X_train = np.load('../sample_training_data/X_train.npy') \n",
    "X_test = np.load('../sample_training_data/X_test.npy')\n",
    "y_train = np.load('../sample_training_data/y_train.npy')\n",
    "y_test = np.load('../sample_training_data/y_test.npy')\n",
    "\n",
    "# print shapes of the data\n",
    "print(f'X_train ... {X_train.shape}')\n",
    "print(f'X_test ... {X_test.shape}')\n",
    "print(f'y_train ... {y_train.shape}')\n",
    "print(f'y_test ... {y_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e50d4f-8fa1-41c2-bd0a-53ecfe1f2497",
   "metadata": {},
   "source": [
    "### input features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd7accef-5bf1-49f5-a902-0c76c234005f",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_train_case_input_data = pd.DataFrame(X_train[0,:,:], columns=['Engine speed (rpm)',\n",
    "'Engine torque (Nm)',\n",
    "'Engine throttle (%)',\n",
    "'Coolant temperature downstream the engine (°C)',\n",
    "'Ambient temperature (°C)',\n",
    "'Temperature of exhaust gases upstream the muffler (°C)',\n",
    "'Temperature of oil in sump (°C)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bfcaf2e4-969b-45b5-882d-e74864ec4fac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Engine speed (rpm)</th>\n",
       "      <th>Engine torque (Nm)</th>\n",
       "      <th>Engine throttle (%)</th>\n",
       "      <th>Coolant temperature downstream the engine (°C)</th>\n",
       "      <th>Ambient temperature (°C)</th>\n",
       "      <th>Temperature of exhaust gases upstream the muffler (°C)</th>\n",
       "      <th>Temperature of oil in sump (°C)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2057.327642</td>\n",
       "      <td>17.814633</td>\n",
       "      <td>17.584523</td>\n",
       "      <td>147.500324</td>\n",
       "      <td>23.303821</td>\n",
       "      <td>-6.030186</td>\n",
       "      <td>-3.794343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2055.507159</td>\n",
       "      <td>17.318986</td>\n",
       "      <td>17.311834</td>\n",
       "      <td>148.640170</td>\n",
       "      <td>23.495001</td>\n",
       "      <td>-6.023304</td>\n",
       "      <td>-3.769398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2049.333314</td>\n",
       "      <td>17.418549</td>\n",
       "      <td>17.344103</td>\n",
       "      <td>148.816810</td>\n",
       "      <td>23.024075</td>\n",
       "      <td>-6.020520</td>\n",
       "      <td>-3.881337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2035.073482</td>\n",
       "      <td>17.045133</td>\n",
       "      <td>17.200031</td>\n",
       "      <td>150.587196</td>\n",
       "      <td>23.157055</td>\n",
       "      <td>-6.017970</td>\n",
       "      <td>-3.897206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2043.999238</td>\n",
       "      <td>17.271089</td>\n",
       "      <td>17.276462</td>\n",
       "      <td>150.251657</td>\n",
       "      <td>22.628901</td>\n",
       "      <td>-6.014743</td>\n",
       "      <td>-3.973748</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Engine speed (rpm)  Engine torque (Nm)  Engine throttle (%)  \\\n",
       "0         2057.327642           17.814633            17.584523   \n",
       "1         2055.507159           17.318986            17.311834   \n",
       "2         2049.333314           17.418549            17.344103   \n",
       "3         2035.073482           17.045133            17.200031   \n",
       "4         2043.999238           17.271089            17.276462   \n",
       "\n",
       "   Coolant temperature downstream the engine (°C)  Ambient temperature (°C)  \\\n",
       "0                                      147.500324                 23.303821   \n",
       "1                                      148.640170                 23.495001   \n",
       "2                                      148.816810                 23.024075   \n",
       "3                                      150.587196                 23.157055   \n",
       "4                                      150.251657                 22.628901   \n",
       "\n",
       "   Temperature of exhaust gases upstream the muffler (°C)  \\\n",
       "0                                          -6.030186        \n",
       "1                                          -6.023304        \n",
       "2                                          -6.020520        \n",
       "3                                          -6.017970        \n",
       "4                                          -6.014743        \n",
       "\n",
       "   Temperature of oil in sump (°C)  \n",
       "0                        -3.794343  \n",
       "1                        -3.769398  \n",
       "2                        -3.881337  \n",
       "3                        -3.897206  \n",
       "4                        -3.973748  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_train_case_input_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1affb19-e081-467a-865c-2816d0256c1f",
   "metadata": {},
   "source": [
    "### output targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c7811e18-60f2-4247-9d36-76da3730c057",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_train_case_output_data = pd.DataFrame(y_train[0,:,:], columns=['Species NOx (ppm)',\n",
    "'Species CO (ppm)',\n",
    "'Species UHC (ppm)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb4a1b03-dae2-4be5-8f25-691cec597041",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Species NOx (ppm)</th>\n",
       "      <th>Species CO (ppm)</th>\n",
       "      <th>Species UHC (ppm)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>669.098823</td>\n",
       "      <td>10613.403525</td>\n",
       "      <td>722.069942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>691.257433</td>\n",
       "      <td>10760.932632</td>\n",
       "      <td>722.126015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>681.596385</td>\n",
       "      <td>10753.549182</td>\n",
       "      <td>723.018856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>690.803062</td>\n",
       "      <td>10857.214719</td>\n",
       "      <td>728.953240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>698.436983</td>\n",
       "      <td>10749.402090</td>\n",
       "      <td>730.281801</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Species NOx (ppm)  Species CO (ppm)  Species UHC (ppm)\n",
       "0         669.098823      10613.403525         722.069942\n",
       "1         691.257433      10760.932632         722.126015\n",
       "2         681.596385      10753.549182         723.018856\n",
       "3         690.803062      10857.214719         728.953240\n",
       "4         698.436983      10749.402090         730.281801"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_train_case_output_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "632f7060-da5f-4fc9-9ab2-da8d0e195831",
   "metadata": {},
   "source": [
    "### Data processing \n",
    " - load the data\n",
    " - Normalize the data\n",
    " - convert them to sequential data\n",
    " - creating train and test data loaders for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b0c31bca-6368-4ae3-9387-4692c92124dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the parent directory to the system path\n",
    "sys.path.append(os.path.abspath('../src'))\n",
    "\n",
    "from data_preprocessing import DataPreprocessor, DataLoaderFact, DataPaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c96e3c26-4d81-4d5c-8d21-4fa63f55bdeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../sample_training_data/X_train.npy\n",
      "X_train ... (17, 484, 80, 7)\n",
      "X_test ... (4, 484, 80, 7)\n",
      "y_train ... (17, 484, 5, 3)\n",
      "y_test ... (4, 484, 5, 3)\n"
     ]
    }
   ],
   "source": [
    "# initialize the data preprocessor\n",
    "paths = DataPaths(base_dir =\"../sample_training_data\")\n",
    "print(paths.X_train)\n",
    "data_preprocessor = DataPreprocessor(paths=paths)\n",
    "\n",
    "# load the raw data\n",
    "X_train, X_test, y_train, y_test = data_preprocessor.data_processing() \n",
    "\n",
    "# print shapes of the data\n",
    "print(f'X_train ... {X_train.shape}')\n",
    "print(f'X_test ... {X_test.shape}')\n",
    "print(f'y_train ... {y_train.shape}')\n",
    "print(f'y_test ... {y_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da22d839-eec5-4e06-ad02-7ff30fe11009",
   "metadata": {},
   "source": [
    "### Data seq to seq transformation\n",
    "- First data is processed to (seq to seq)\n",
    "- convert to train and test loaders for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9e987738-d0da-4feb-8bab-901e81289839",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loader Batch Shapes:\n",
      "Training data is converted to batches for better processing\n",
      "Batch 1 - inputs: torch.Size([256, 80, 7]), targets: torch.Size([256, 5, 3])\n",
      "Batch 2 - inputs: torch.Size([256, 80, 7]), targets: torch.Size([256, 5, 3])\n",
      "Batch 3 - inputs: torch.Size([256, 80, 7]), targets: torch.Size([256, 5, 3])\n",
      "Batch 4 - inputs: torch.Size([256, 80, 7]), targets: torch.Size([256, 5, 3])\n",
      "Batch 5 - inputs: torch.Size([256, 80, 7]), targets: torch.Size([256, 5, 3])\n",
      "Batch 6 - inputs: torch.Size([256, 80, 7]), targets: torch.Size([256, 5, 3])\n",
      "Batch 7 - inputs: torch.Size([256, 80, 7]), targets: torch.Size([256, 5, 3])\n",
      "Batch 8 - inputs: torch.Size([256, 80, 7]), targets: torch.Size([256, 5, 3])\n",
      "Batch 9 - inputs: torch.Size([256, 80, 7]), targets: torch.Size([256, 5, 3])\n",
      "Batch 10 - inputs: torch.Size([256, 80, 7]), targets: torch.Size([256, 5, 3])\n",
      "Batch 11 - inputs: torch.Size([256, 80, 7]), targets: torch.Size([256, 5, 3])\n",
      "Batch 12 - inputs: torch.Size([256, 80, 7]), targets: torch.Size([256, 5, 3])\n",
      "Batch 13 - inputs: torch.Size([256, 80, 7]), targets: torch.Size([256, 5, 3])\n",
      "Batch 14 - inputs: torch.Size([256, 80, 7]), targets: torch.Size([256, 5, 3])\n",
      "Batch 15 - inputs: torch.Size([256, 80, 7]), targets: torch.Size([256, 5, 3])\n",
      "Batch 16 - inputs: torch.Size([256, 80, 7]), targets: torch.Size([256, 5, 3])\n",
      "Batch 17 - inputs: torch.Size([256, 80, 7]), targets: torch.Size([256, 5, 3])\n",
      "Batch 18 - inputs: torch.Size([256, 80, 7]), targets: torch.Size([256, 5, 3])\n",
      "Batch 19 - inputs: torch.Size([256, 80, 7]), targets: torch.Size([256, 5, 3])\n",
      "Batch 20 - inputs: torch.Size([256, 80, 7]), targets: torch.Size([256, 5, 3])\n",
      "Batch 21 - inputs: torch.Size([256, 80, 7]), targets: torch.Size([256, 5, 3])\n",
      "Batch 22 - inputs: torch.Size([256, 80, 7]), targets: torch.Size([256, 5, 3])\n",
      "Batch 23 - inputs: torch.Size([256, 80, 7]), targets: torch.Size([256, 5, 3])\n",
      "Batch 24 - inputs: torch.Size([256, 80, 7]), targets: torch.Size([256, 5, 3])\n",
      "Batch 25 - inputs: torch.Size([256, 80, 7]), targets: torch.Size([256, 5, 3])\n",
      "Batch 26 - inputs: torch.Size([256, 80, 7]), targets: torch.Size([256, 5, 3])\n",
      "Batch 27 - inputs: torch.Size([256, 80, 7]), targets: torch.Size([256, 5, 3])\n",
      "Batch 28 - inputs: torch.Size([256, 80, 7]), targets: torch.Size([256, 5, 3])\n",
      "Batch 29 - inputs: torch.Size([256, 80, 7]), targets: torch.Size([256, 5, 3])\n",
      "Batch 30 - inputs: torch.Size([256, 80, 7]), targets: torch.Size([256, 5, 3])\n",
      "Batch 31 - inputs: torch.Size([256, 80, 7]), targets: torch.Size([256, 5, 3])\n",
      "Batch 32 - inputs: torch.Size([256, 80, 7]), targets: torch.Size([256, 5, 3])\n",
      "Batch 33 - inputs: torch.Size([36, 80, 7]), targets: torch.Size([36, 5, 3])\n",
      "\n",
      "Test Loader Batch Shapes:\n",
      "All Testing data is processed in one batch for results\n",
      "Batch 1 - inputs: torch.Size([1936, 80, 7]), targets: torch.Size([1936, 5, 3])\n"
     ]
    }
   ],
   "source": [
    "# Create data loaders\n",
    "train_loader, test_loader = DataLoaderFact.create_loaders(X_train, X_test, y_train, y_test)\n",
    "\n",
    "# For train loader\n",
    "print(\"Train Loader Batch Shapes:\")\n",
    "print(\"Training data is converted to batches for better processing\")\n",
    "for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
    "    print(f\"Batch {batch_idx + 1} - inputs: {inputs.shape}, targets: {targets.shape}\")  \n",
    "\n",
    "# For test loader\n",
    "print(\"\\nTest Loader Batch Shapes:\")\n",
    "print(\"All Testing data is processed in one batch for results\")\n",
    "for batch_idx, (inputs, targets) in enumerate(test_loader):\n",
    "    print(f\"Batch {batch_idx + 1} - inputs: {inputs.shape}, targets: {targets.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "837b2c43-4252-4f39-87b8-7900f9755477",
   "metadata": {},
   "source": [
    "### detail inspection of batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "83015205-e9d0-4a05-af3d-4ff7d0930004",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the parent directory to the system path\n",
    "sys.path.append(os.path.abspath('../src'))\n",
    "\n",
    "from training_evaluation_plotting import inspect_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7f1cdde3-4611-4dec-80d2-c3da21903065",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Inspecting 2 batches from train_loader\n",
      "Total batches: 33\n",
      "Batch size: 256\n",
      "==================================================\n",
      "\n",
      "Batch 1:\n",
      "  Input shape: torch.Size([256, 80, 7]) (batch_size, seq_len, features)\n",
      "  Target shape: torch.Size([256, 5, 3])\n",
      "  Input dtype: torch.float32, Target dtype: torch.float32\n",
      "  Input range: [-1.8166, 2.8380]\n",
      "  Target range: [-1.9229, 3.0508]\n",
      "\n",
      "  Sample Sequence (First in batch):\n",
      "  Input[0, 0]: [ 0.5923 -0.1345  0.325   0.4554  1.3228  1.405   1.4792]\n",
      "  Input[0, -1]: [ 0.6516 -0.0642  0.0785  0.5094  1.2192  1.4044  1.4515]\n",
      "  Target[0, 0]: [ 0.2353 -0.8115 -1.1769]\n",
      "----------------------------------------\n",
      "\n",
      "Batch 2:\n",
      "  Input shape: torch.Size([256, 80, 7]) (batch_size, seq_len, features)\n",
      "  Target shape: torch.Size([256, 5, 3])\n",
      "  Input dtype: torch.float32, Target dtype: torch.float32\n",
      "  Input range: [-1.8166, 3.1850]\n",
      "  Target range: [-1.9620, 2.9383]\n",
      "\n",
      "  Sample Sequence (First in batch):\n",
      "  Input[0, 0]: [0.9069 0.5328 0.3916 0.8513 1.4555 1.408  1.4594]\n",
      "  Input[0, -1]: [0.6953 0.431  0.5347 0.9309 1.4823 1.4048 1.5257]\n",
      "  Target[0, 0]: [ 0.1544 -1.5624 -1.3566]\n",
      "----------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Inspect batches before training\n",
    "inspect_batches(train_loader, num_batches=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b000ca-e0e7-46fe-becf-174f0a1506b1",
   "metadata": {},
   "source": [
    "### training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6efde456-2608-41ab-bbd8-019a5be57835",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Epoch [1/50], Train Loss: 0.1734, Val Loss: 0.2048\n",
      "Epoch [2/50], Train Loss: 0.1559, Val Loss: 0.1385\n",
      "Epoch [3/50], Train Loss: 0.0959, Val Loss: 0.0684\n",
      "Epoch [4/50], Train Loss: 0.0520, Val Loss: 0.0637\n",
      "Epoch [5/50], Train Loss: 0.0400, Val Loss: 0.0723\n",
      "Epoch [6/50], Train Loss: 0.0355, Val Loss: 0.0756\n",
      "Epoch [7/50], Train Loss: 0.0336, Val Loss: 0.0692\n",
      "Epoch [8/50], Train Loss: 0.0324, Val Loss: 0.0640\n",
      "Epoch [9/50], Train Loss: 0.0318, Val Loss: 0.0602\n",
      "Epoch [10/50], Train Loss: 0.0315, Val Loss: 0.0591\n",
      "Epoch [11/50], Train Loss: 0.0309, Val Loss: 0.0541\n",
      "Epoch [12/50], Train Loss: 0.0306, Val Loss: 0.0565\n",
      "Epoch [13/50], Train Loss: 0.0306, Val Loss: 0.0552\n",
      "Epoch [14/50], Train Loss: 0.0306, Val Loss: 0.0567\n",
      "Epoch [15/50], Train Loss: 0.0304, Val Loss: 0.0563\n",
      "Epoch [16/50], Train Loss: 0.0301, Val Loss: 0.0541\n",
      "Epoch [17/50], Train Loss: 0.0300, Val Loss: 0.0554\n",
      "Epoch [18/50], Train Loss: 0.0299, Val Loss: 0.0541\n",
      "Epoch [19/50], Train Loss: 0.0297, Val Loss: 0.0549\n",
      "Epoch [20/50], Train Loss: 0.0293, Val Loss: 0.0525\n",
      "Epoch [21/50], Train Loss: 0.0291, Val Loss: 0.0536\n",
      "Epoch [22/50], Train Loss: 0.0291, Val Loss: 0.0517\n",
      "Epoch [23/50], Train Loss: 0.0291, Val Loss: 0.0556\n",
      "Epoch [24/50], Train Loss: 0.0290, Val Loss: 0.0533\n",
      "Epoch [25/50], Train Loss: 0.0289, Val Loss: 0.0544\n",
      "Epoch [26/50], Train Loss: 0.0285, Val Loss: 0.0538\n",
      "Epoch [27/50], Train Loss: 0.0286, Val Loss: 0.0536\n",
      "Epoch [28/50], Train Loss: 0.0283, Val Loss: 0.0507\n",
      "Epoch [29/50], Train Loss: 0.0284, Val Loss: 0.0529\n",
      "Epoch [30/50], Train Loss: 0.0282, Val Loss: 0.0510\n",
      "Epoch [31/50], Train Loss: 0.0281, Val Loss: 0.0525\n",
      "Epoch [32/50], Train Loss: 0.0279, Val Loss: 0.0537\n",
      "Epoch [33/50], Train Loss: 0.0279, Val Loss: 0.0515\n",
      "Epoch [34/50], Train Loss: 0.0278, Val Loss: 0.0508\n",
      "Epoch [35/50], Train Loss: 0.0283, Val Loss: 0.0530\n",
      "Epoch [36/50], Train Loss: 0.0280, Val Loss: 0.0530\n",
      "Epoch [37/50], Train Loss: 0.0278, Val Loss: 0.0532\n",
      "Epoch [38/50], Train Loss: 0.0279, Val Loss: 0.0528\n",
      "Epoch [39/50], Train Loss: 0.0278, Val Loss: 0.0513\n",
      "Epoch [40/50], Train Loss: 0.0278, Val Loss: 0.0503\n",
      "Epoch [41/50], Train Loss: 0.0279, Val Loss: 0.0482\n",
      "Epoch [42/50], Train Loss: 0.0278, Val Loss: 0.0528\n",
      "Epoch [43/50], Train Loss: 0.0279, Val Loss: 0.0531\n",
      "Epoch [44/50], Train Loss: 0.0276, Val Loss: 0.0531\n",
      "Epoch [45/50], Train Loss: 0.0274, Val Loss: 0.0538\n",
      "Epoch [46/50], Train Loss: 0.0274, Val Loss: 0.0521\n",
      "Epoch [47/50], Train Loss: 0.0278, Val Loss: 0.0529\n",
      "Epoch [48/50], Train Loss: 0.0275, Val Loss: 0.0531\n",
      "Epoch [49/50], Train Loss: 0.0274, Val Loss: 0.0546\n",
      "Epoch [50/50], Train Loss: 0.0274, Val Loss: 0.0539\n",
      "Best model at epoch 41 with training loss 0.0482\n",
      "Kept only model from epoch 41. Others deleted.\n",
      "\n",
      "Training completed in 0m 18.72s\n",
      "Best validation loss: inf\n"
     ]
    }
   ],
   "source": [
    "from training_evaluation_plotting import train_model\n",
    "\n",
    "# initialize the model\n",
    "model_params = {\n",
    "    'input_dim': 7,\n",
    "    'output_dim': 3,\n",
    "    'hidden_dim': 128,\n",
    "    'num_layers': 2,\n",
    "    'dropout': 0.2,\n",
    "    'learning_rate': 0.0001,\n",
    "    'num_epochs': 50,\n",
    "    'output_length': 5\n",
    "} \n",
    "# Train the model   \n",
    "model, train_losses, val_losses = train_model(\n",
    "    train_loader,\n",
    "    test_loader,\n",
    "    model_params=model_params\n",
    ") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c2b96bf-f125-44fc-aaab-84db06812614",
   "metadata": {},
   "source": [
    "### evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7192c132-f785-4e20-8926-045b6785ca55",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hkfs/home/project/hk-project-consulting/is1941/03_test_before_paper_submission/src/training_evaluation_plotting.py:267: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n"
     ]
    }
   ],
   "source": [
    "from training_evaluation_plotting import evaluate_model, load_model\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Load model\n",
    "model_paths = glob.glob(\"saved_models/*.pth\")\n",
    "if not model_paths:\n",
    "    raise FileNotFoundError(\"No saved model found in 'saved_models/' directory.\")\n",
    "model = load_model(model_paths[0], model_params['input_dim'],\n",
    "                   model_params['output_dim'], \n",
    "                   model_params['hidden_dim'],\n",
    "                   model_params['num_layers'],\n",
    "                   model_params['dropout'],\n",
    "                   model_params['output_length'], device)\n",
    "# Evaluate model\n",
    "predictions, actuals = evaluate_model(model, test_loader, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a667120-cb6b-4b07-94c2-d8aa0a8ee57d",
   "metadata": {},
   "source": [
    "### data transform for Metrics R2, RMSE, MAE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d76b1f19-2620-421e-9e0c-32605e797b55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shpae of actuals: (9680, 3)\n",
      "shpae of predictions: (9680, 3)\n",
      "Shapes: actuals (4, 2420, 3), predictions (4, 2420, 3)\n",
      "\n",
      "Metrics for NO:\n",
      "R2: [-0.132, -0.107, -1.092, -7.387]\n",
      "RMSE: [13090613.0, 11182808.0, 13384478.0, 26551918.0]\n",
      "MAE: [11054394.0, 9098706.0, 10895646.0, 24945130.0]\n",
      "\n",
      "Metrics for CO:\n",
      "R2: [-0.23, -0.082, -3.946, -0.094]\n",
      "RMSE: [3387234560.0, 3786436608.0, 5515828736.0, 1746410368.0]\n",
      "MAE: [2733583872.0, 2978628352.0, 4956944384.0, 1466064640.0]\n",
      "\n",
      "Metrics for UHC:\n",
      "R2: [-1.275, -0.042, -0.944, -49.541]\n",
      "RMSE: [3329665.75, 4093633.25, 2430890.5, 4099068.0]\n",
      "MAE: [2900034.0, 3257103.25, 1994135.5, 4058273.75]\n"
     ]
    }
   ],
   "source": [
    "from training_evaluation_plotting import inverse_transform, reshape_data, calculate_metrics\n",
    "\n",
    "# Data Transformation\n",
    "sc = data_preprocessor.y_scaler\n",
    "actuals = inverse_transform(reshape_data(actuals, (-1, model_params['output_dim'])), sc)\n",
    "predictions = inverse_transform(reshape_data(predictions, (-1, model_params['output_dim'])), sc)\n",
    "print(f'shpae of actuals: {actuals.shape}')\n",
    "print(f'shpae of predictions: {predictions.shape}')\n",
    "\n",
    "# Reshape for metric calculation\n",
    "reshaped_for_metrics = (4, 2420, 3)\n",
    "actuals_final = reshape_data(actuals, reshaped_for_metrics)\n",
    "preds_final = reshape_data(predictions, reshaped_for_metrics)\n",
    "print(f\"Shapes: actuals {actuals_final.shape}, predictions {preds_final.shape}\")\n",
    "\n",
    "# Metrics calculation\n",
    "total_steps = actuals.shape[0]\n",
    "metrics = calculate_metrics(actuals, predictions, total_steps)\n",
    "\n",
    "# Print metrics\n",
    "gases = ['NO', 'CO', 'UHC']\n",
    "for idx, gas in enumerate(gases):\n",
    "    print(f\"\\nMetrics for {gas}:\")\n",
    "    print(f\"R2: { [val[idx] for val in metrics['R2']] }\")\n",
    "    print(f\"RMSE: { [val[idx] for val in metrics['RMSE']] }\")\n",
    "    print(f\"MAE: { [val[idx] for val in metrics['MAE']] }\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58a5b4fc-a2eb-4a43-a920-5a71796289d8",
   "metadata": {},
   "source": [
    "### plotting the results to folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d51d70db-27fb-45ee-8262-af9b503c0c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "from training_evaluation_plotting import range_with_floats, get_formatter, create_plots\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "\n",
    "# Plot results\n",
    "time_series = range_with_floats(0, 800, 0.2)[:2420]\n",
    "# Formatters\n",
    "formatter_y = get_formatter((-4, 4))\n",
    "create_plots(\n",
    "    data_indices=[1, 0],\n",
    "    titles=['-15$^\\\\circ$C', '-7$^\\\\circ$C'],\n",
    "    output_filename='plots1.png',\n",
    "    actuals_final=actuals_final,\n",
    "    preds_final=preds_final,\n",
    "    metrics=metrics,\n",
    "    time_seconds=time_series,\n",
    "    formatter_y=formatter_y\n",
    ")\n",
    "\n",
    "create_plots(\n",
    "    data_indices=[2, 3],\n",
    "    titles=['0$^\\\\circ$C', '23$^\\\\circ$C'],\n",
    "    output_filename='plots2.png',\n",
    "    actuals_final=actuals_final,\n",
    "    preds_final=preds_final,\n",
    "    metrics=metrics,\n",
    "    time_seconds=time_series,\n",
    "    formatter_y=formatter_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c081efb-a69f-4a58-a092-2916fbb953cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
